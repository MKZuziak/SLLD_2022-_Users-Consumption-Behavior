legend.title = "contrib", legend.position = "top",
ggtheme = theme_minimal())
ggbiplot(res,ellipse = TRUE, varname.size = 2, alpha = 0.3)
eu_data <- dist(data_log, method='euclidean')
#class(eu_iris) # note: this is not a matrix, but an object of a specific class
hc_single   <- hclust(eu_data, method='single')     # single linkage
hc_complete <- hclust(eu_data, method='complete')   # complete linkage
hc_average  <- hclust(eu_data, method='average')    # average linkage
hc_centroid <- hclust(eu_data, method='centroid')   # centroid linkage
str(hc_single)            # it's a list
head(hc_single$merge, 10) # see the first 10 aggregations
# to see its interpretation, check the "Value" (i.e., output) paragraph in here:
# help(hclust)
# par(mfrow=c(2,2))
fviz_dend(hc_single,   as.ggplot = TRUE, show_labels = FALSE, main='Euclidean-Single')
fviz_dend(hc_complete, as.ggplot = TRUE, show_labels = FALSE, main='Euclidean-Complete')
fviz_dend(hc_average,  as.ggplot = TRUE, show_labels = FALSE, main='Euclidean-Average')
fviz_dend(hc_centroid, as.ggplot = TRUE, show_labels = FALSE, main='Euclidean-Centroid')
cluster_k <- cutree(hc_complete, k = 3)     # identify 2 groups
cluster_k
fviz_dend(hc_complete, k = 3, k_colors = "jco",
as.ggplot = TRUE, show_labels = FALSE,
main='Euclidean-Complete')
clHeight <- 34
cluster_h <- cutree(hc_complete, h = clHeight)    #identify groups below a certain height
cluster_h
fviz_dend(hc_complete, h = clHeight, k_colors = "jco",
as.ggplot = TRUE, show_labels = FALSE,
main='Euclidean-Complete')+
geom_hline(yintercept = clHeight, linetype = 2, col="red")
hc_diana <- diana(eu_data)
str(hc_diana)
class(hc_diana)       # notice its difference from class(hc_centroid) etc.
head(hc_diana$merge)
hc_centroid
res <- kmeans(data_log, 3)
fviz_dend(hc_diana, as.ggplot = TRUE,
show_labels = FALSE, main='Euclidean-Complete') # plot the dendrogram
cluster_diana <- cutree(hc_diana, k=3)                    # cut by k (with height? Error)
cluster_diana
cluster_diana <- cutree(as.hclust(hc_diana), h=5.5)       # cut by height (NOTE: convert it)
cluster_diana
res <- kmeans(data_log, 3, nstart = 10)
hc_res <- eclust(data_log,                        # data
"hclust",                     # method
k = 3,                        # num. of clusters
hc_metric = "euclidean",      # distance measure
hc_method = "complete")         # linkage function
str(hc_res)
hc_res$cluster
fviz_dend(hc_res, as.ggplot = TRUE,
show_labels = FALSE,
main='Euclidean-Single with eclust') # plot the dendrogram
res <- kmeans(data_log, 3, nstart = 10)
res$cluster
png("myplot.png", width=4, height=4, units="in", res=300)
par(mar=c(4,4,1,1))
#plot(data_log, col =(res$cluster +1) , main="K-Means Clustering Results with K=3", pch =20, cex =0.5)
dev.off() #only 129kb in size
data_log
# it receives data, algorithm, k, distance to compute
km_res <- eclust(data_log[,2:53], "kmeans", k = 3, hc_metric = "euclidean")
# it receives data, algorithm, k, distance to compute
km_res <- eclust(data_log, "kmeans", k = 3, hc_metric = "euclidean")
km_res$cluster
distance <- dist(data_log, method="euclidean")
sil <- silhouette(x = res$cluster, dist = distance)
fviz_silhouette(sil)
fviz_nbclust(data_log, hcut, method = "wss") +
geom_vline(xintercept = 3, linetype = 2)
fviz_nbclust(data_log, kmeans, method = "wss") +
geom_vline(xintercept = 3, linetype = 2)
harAHC <- NbClust(data_log,  distance = "euclidean", method = "complete", index='hartigan')
plot(harAHC$All.index, type = "l")
abline(v=harAHC$Best.nc[1], col="blue", lty=2)
harKM <- NbClust(data_log,  distance = "euclidean", method = "kmeans", index='hartigan')
plot(harKM$All.index, type = "l")
abline(v=harKM$Best.nc[1], col="blue", lty=2)
allKM <- NbClust(data_log,  distance = "euclidean", method = "kmeans", index='all')
fviz_nbclust(data_log, kmeans, method = "silhouette")+
labs(subtitle = "Silhouette method k-means")
# Silhouette method
fviz_nbclust(data_log, hcut, method = "silhouette")+
labs(subtitle = "Silhouette method AHC")
plot(pressure)
knitr::opts_chunk$set(echo = TRUE)
library(tibble)
library(mvtnorm)
library(factoextra)
library(scales)
library(ellipse)
library(corrplot)
library(ggplot2)
library(dplyr)
library(rrcov)
library(stats)
library(lares)
library(glmnet)
library(ggpubr)
library(cluster)
library(NbClust)
#library(ggbiplot)
Users.Consumption.Behavior._2019 <- read.csv("~/GitHub/SLLD_2022-_Users-Consumption-Behavior/Users Consumption Behavior _2019.csv")
View(Users.Consumption.Behavior._2019)
head(Users.Consumption.Behavior._2019)
knitr::opts_chunk$set(echo = TRUE)
library(tibble)
library(mvtnorm)
library(factoextra)
library(scales)
library(ellipse)
library(corrplot)
library(ggplot2)
library(dplyr)
library(rrcov)
library(stats)
library(lares)
library(glmnet)
library(ggpubr)
library(cluster)
library(NbClust)
#library(ggbiplot)
head(Users.Consumption.Behavior._2019)
data <- Users.Consumption.Behavior._2019
head(data)
data[,114]
sum(is.na(data))
sum(is.null(data))
dict <- sapply(data, n_distinct)
print(class(dict))
dict
# Detaching column containing clusters (column no. 114)
Users_data_overview <- data[,1:113]
data_copy <- Users_data_overview
data <- data_copy
column_names <- c(names(data_copy))
column_names = column_names[2:113]
columns_overview = data.frame(df=column_names)
missing_values = c()
for(i in 2:ncol(Users_data_overview)){
# Null_values(0)
sums_zero = sum(data_copy[, i] == 0)
missing_val = sums_zero
missing_values = append(missing_values, missing_val)
}
columns_overview$null_values <- c(missing_values)
sorted_overview <-columns_overview[order(columns_overview$null_values, decreasing=FALSE),]
sorted_overview
hist(sorted_overview$null_values,
main = "Histogram for missing values",
xlab = "No. of missing values",
border = "blue",
col = "green",
breaks = 10)
uniquelength <- sapply(data,function(x) length(unique(x)))
data <- subset(data, select=uniquelength>2)
data
uniquelength <- sapply(data,function(x) length(unique(x)))
data <- subset(data, select=uniquelength>2)
data
dict <- sapply(data, n_distinct)
print(class(dict))
dict[0:106]
hist(dict[0:106],
main = "Histogram for missing values",
xlab = "No. of missing values",
border = "blue",
col = "green",
breaks = 10)
colClean <- function(x){ colnames(x) <- gsub("_occupation", "", colnames(x)); x }
data <- colClean(data)
data_pca <- data[,2:106]
res <- prcomp(data_pca, scale = TRUE)
get_eig(res)
fviz_eig(res)
fviz_eig(res, ncp = 25)
plot(get_eig(res)$cumulative.variance.percent,
type='b', axes=F, xlab='Dimensions', ylab='cumulative PVE', ylim=c(0,100))
abline(h=100, col=alpha('blue',0.5))
abline(h=80, lty=2, col='red', lwd=2) # thresholding
box()
axis(2, at=0:100,labels=0:100)
axis(1,at=1:ncol(data_pca),labels=1:ncol(data_pca))
grid()
varpca <- get_pca_var(res)
varpca <- varpca$cos2
varpca <- as.data.frame(varpca)
varpca <- t(varpca)
varpca <- as.data.frame(varpca)
corr_cross(varpca, max_pvalue = 0.05, top = 20)
fviz_pca_var(res,
col.var = "contrib", # Color by contributions to the PC
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), geom = c('point'),
repel = TRUE, title="PCA:2D - Contribution plot of the all variables")    # Avoid text overlapping
fviz_pca_var(res,
col.var = "contrib", # Color by contributions to the PC
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE, select.var = list(contrib = 10), title="PCA:2D - Contribution plot of the top 10 contributing active variables [arrow + text]")
fviz_pca_var(res,
col.var = "contrib", # Color by contributions to the PC
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE, geom = c('point', 'text'), select.var = list(contrib = 10), title="PCA:2D - Contribution plot of the top 10 contributing active variables [point + text]")
fviz_pca_biplot(res,
col.var = "contrib", # Color by contributions to the PC
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE, select.var = list(contrib = 10), select.ind = list(contrib = 30), title="PCA:2D - Contribution plot of the top 10 contributing active variables and 30 individuals")
fviz_pca_biplot(res,
col.var = "contrib", # Color by contributions to the PC
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = FALSE, title="PCA:2D - Complete Biplot")
sum_time <- data.frame(total_time = rowSums(data[,2:53], na.rm = FALSE, dims=1))
hist(sum_time[,1],
main = "TOTAL TIME OCCUPATION PER USER",
xlab = "TIME OCCUPATION",
ylab = "NUMBER OF USERS",
border = "blue",
col = "green",
breaks = 100)
hist(sum_time[,1],
main = "TOTAL TIME OCCUPATION PER USER (Freedman-Diaconis)",
xlab = "TIME OCCUPATION",
ylab = "NUMBER OF USERS",
breaks="FD",
border = "blue",
col = "green")
sum_cat <- data.frame(total_time = colSums(data[, 2:53], na.rm = FALSE, dims=1))
hist(sum_cat[,1],
main = "TOTAL TIME OCCUPATION PER PLATFORM",
xlab = "TIME OCCUPATION",
ylab = "NUMBER OF PLATFORMS",
border = "blue",
breaks = 100,
col = "green")
sum_cat <- data.frame(total_time = colSums(data[, 2:53], na.rm = FALSE, dims=1))
hist(sum_cat[,1],
main = "TOTAL TIME OCCUPATION PER PLATFORM (Freedman-Diaconis)",
xlab = "TIME OCCUPATION",
ylab = "NUMBER OF PLATFORMS",
border = "blue",
breaks = "FD",
col = "green")
rn <- runif(1)
data_new <- data + rn
#summary(data_new)
data_log <- log(data_new[,2:53])
#summary(data_log)
#data_sc_log<- scale(data_log)
rn
rn <- runif(1)
data_new <- data + rn
#summary(data_new)
data_log <- log(data_new[,2:53])
#summary(data_log)
#data_sc_log<- scale(data_log)
#data_log = add_column(data_log, data[, 1], after = 52)
data_log
sum_time <- data.frame(total_time = rowSums(data_log, na.rm = FALSE, dims=1))
hist(sum_time[,1],
main = "TOTAL TIME OCCUPATION PER USER (LOG TRANSFORMATION)",
xlab = "TIME OCCUPATION",
ylab = "NUMBER OF USERS",
border = "blue",
col = "green",
breaks = 100)
hist(sum_time[,1],
main = "TOTAL TIME OCCUPATION PER USER (Freedman-Diaconis)",
xlab = "TIME OCCUPATION",
ylab = "NUMBER OF USERS",
breaks="FD",
border = "blue",
col = "green")
sum_cat <- data.frame(total_time = colSums(data_log, na.rm = FALSE, dims=1))
hist(sum_cat[,1],
main = "TOTAL TIME OCCUPATION PER PLATFORM (LOG TRANSFORMATION)",
xlab = "TIME OCCUPATION",
ylab = "NUMBER OF PLATFORMS",
border = "blue",
breaks = 100,
col = "green")
sum_cat <- data.frame(total_time = colSums(data_log, na.rm = FALSE, dims=1))
hist(sum_cat[,1],
main = "TOTAL TIME OCCUPATION PER PLATFORM (Freedman-Diaconis)",
xlab = "TIME OCCUPATION",
ylab = "NUMBER OF PLATFORMS",
border = "blue",
breaks = "FD",
col = "green")
#correlation for just a few features
library(corrplot)
M<-cor(data_log[,2:5])
head(round(M,2))
#first type of correlation plot
corrplot(M, method="circle")
#second type of correlation plot
corrplot(M, method="number")
###Removing highly correlated variables
###Removing highly correlated variable#### It needs to be tested
cor_matrix <- cor(data_log)  # Correlation matrix
cor_matrix
library(ggbiplot)
res <- prcomp(data_log, scale = FALSE)
loadings <- res$rotation
plot.new()
varpca <- get_pca_var(res)
varpca
corrplot(varpca$contrib, is.corr=FALSE)
corrplot(varpca$cos2, is.corr=FALSE)
fviz_cos2(res,choice = "var", axes = 2)
#A high cos2 indicates a good representation of the variable
#on the principal component.
#A low cos2 indicates that the variable is not perfectly
#represented by the PCs.
fviz_contrib(res, choice = "var", axes = 1, top =20)
fviz_contrib(res, choice = "var", axes = 2, top =20)
#The red dashed line on the graph above indicates the expected average contribution.
#corrplot(varpca$contrib, is.corr=FALSE)
#corrplot(varpca$cor, is.corr=FALSE)
fviz_pca_ind(res, col.ind = "cos2",
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE # Avoid text overlapping (slow if many points)
)
#eigenvalue
get_eig(res)
####Screen Plot ###
fviz_eig(res, addlabels = TRUE)
plot(get_eig(res)$cumulative.variance.percent,
type='b', axes=F, xlab='Dimensions', ylab='cumulative PVE', ylim=c(0,100))
abline(h=100, col=alpha('blue',0.5))
abline(h=80, lty=2, col='red', lwd=2) # thresholding
box()
axis(2, at=0:100,labels=0:100)
axis(1,at=1:ncol(data[,2:53]),labels=1:ncol(data[,2:53]))
grid()## too many features that should be selected
####Biplot
a <- fviz_pca_var(res,
col.var = "contrib", # Color by contributions to the PC
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
repel = TRUE ,label = "all")    # Avoid text overlapping
ggpar(a,
title = "Principal Component Analysis",
xlab = "PC1", ylab = "PC2",
legend.title = "contrib", legend.position = "top",
ggtheme = theme_minimal())
ggbiplot(res,ellipse = TRUE, varname.size = 2, alpha = 0.3)
eu_data <- dist(data_log, method='euclidean')
#class(eu_iris) # note: this is not a matrix, but an object of a specific class
hc_single   <- hclust(eu_data, method='single')     # single linkage
hc_complete <- hclust(eu_data, method='complete')   # complete linkage
hc_average  <- hclust(eu_data, method='average')    # average linkage
hc_centroid <- hclust(eu_data, method='centroid')   # centroid linkage
str(hc_single)            # it's a list
head(hc_single$merge, 10) # see the first 10 aggregations
# to see its interpretation, check the "Value" (i.e., output) paragraph in here:
# help(hclust)
# par(mfrow=c(2,2))
fviz_dend(hc_single,   as.ggplot = TRUE, show_labels = FALSE, main='Euclidean-Single')
fviz_dend(hc_complete, as.ggplot = TRUE, show_labels = FALSE, main='Euclidean-Complete')
fviz_dend(hc_average,  as.ggplot = TRUE, show_labels = FALSE, main='Euclidean-Average')
fviz_dend(hc_centroid, as.ggplot = TRUE, show_labels = FALSE, main='Euclidean-Centroid')
cluster_k <- cutree(hc_complete, k = 3)     # identify 2 groups
cluster_k
fviz_dend(hc_complete, k = 3, k_colors = "jco",
as.ggplot = TRUE, show_labels = FALSE,
main='Euclidean-Complete')
clHeight <- 34
cluster_h <- cutree(hc_complete, h = clHeight)    #identify groups below a certain height
cluster_h
fviz_dend(hc_complete, h = clHeight, k_colors = "jco",
as.ggplot = TRUE, show_labels = FALSE,
main='Euclidean-Complete')+
geom_hline(yintercept = clHeight, linetype = 2, col="red")
hc_diana <- diana(eu_data)
str(hc_diana)
class(hc_diana)       # notice its difference from class(hc_centroid) etc.
head(hc_diana$merge)
hc_centroid
res <- kmeans(data_log, 3)
fviz_dend(hc_diana, as.ggplot = TRUE,
show_labels = FALSE, main='Euclidean-Complete') # plot the dendrogram
cluster_diana <- cutree(hc_diana, k=3)                    # cut by k (with height? Error)
cluster_diana
cluster_diana <- cutree(as.hclust(hc_diana), h=5.5)       # cut by height (NOTE: convert it)
cluster_diana
res <- kmeans(data_log, 3, nstart = 10)
hc_res <- eclust(data_log,                        # data
"hclust",                     # method
k = 3,                        # num. of clusters
hc_metric = "euclidean",      # distance measure
hc_method = "complete")         # linkage function
str(hc_res)
hc_res$cluster
fviz_dend(hc_res, as.ggplot = TRUE,
show_labels = FALSE,
main='Euclidean-Single with eclust') # plot the dendrogram
res <- kmeans(data_log, 3, nstart = 10)
res$cluster
png("myplot.png", width=4, height=4, units="in", res=300)
par(mar=c(4,4,1,1))
#plot(data_log, col =(res$cluster +1) , main="K-Means Clustering Results with K=3", pch =20, cex =0.5)
dev.off() #only 129kb in size
data_log
# it receives data, algorithm, k, distance to compute
km_res <- eclust(data_log, "kmeans", k = 3, hc_metric = "euclidean")
km_res$cluster
distance <- dist(data_log, method="euclidean")
sil <- silhouette(x = res$cluster, dist = distance)
fviz_silhouette(sil)
fviz_nbclust(data_log, hcut, method = "wss") +
geom_vline(xintercept = 3, linetype = 2)
fviz_nbclust(data_log, kmeans, method = "wss") +
geom_vline(xintercept = 3, linetype = 2)
harAHC <- NbClust(data_log,  distance = "euclidean", method = "complete", index='hartigan')
plot(harAHC$All.index, type = "l")
abline(v=harAHC$Best.nc[1], col="blue", lty=2)
harKM <- NbClust(data_log,  distance = "euclidean", method = "kmeans", index='hartigan')
plot(harKM$All.index, type = "l")
abline(v=harKM$Best.nc[1], col="blue", lty=2)
allKM <- NbClust(data_log,  distance = "euclidean", method = "kmeans", index='all')
fviz_nbclust(data_log, kmeans, method = "silhouette")+
labs(subtitle = "Silhouette method k-means")
# Silhouette method
fviz_nbclust(data_log, hcut, method = "silhouette")+
labs(subtitle = "Silhouette method AHC")
plot(pressure)
knitr::opts_chunk$set(echo = TRUE)
library(tibble)
library(mvtnorm)
library(factoextra)
library(scales)
library(ellipse)
library(corrplot)
library(ggplot2)
library(dplyr)
library(rrcov)
library(stats)
library(lares)
library(glmnet)
library(ggpubr)
library(cluster)
library(NbClust)
#library(ggbiplot)
data <- Users.Consumption.Behavior._2019
head(data)
data[,114]
sum_time <- data.frame(total_time = rowSums(data_log, na.rm = FALSE, dims=1))
hist(sum_time[,1],
main = "TOTAL TIME OCCUPATION PER USER (LOG TRANSFORMATION)",
xlab = "TIME OCCUPATION",
ylab = "NUMBER OF USERS",
border = "blue",
col = "green",
breaks = 100)
hist(sum_time[,1],
main = "TOTAL TIME OCCUPATION PER USER (Freedman-Diaconis)",
xlab = "TIME OCCUPATION",
ylab = "NUMBER OF USERS",
breaks="FD",
border = "blue",
col = "green")
sum_cat <- data.frame(total_time = colSums(data_log, na.rm = FALSE, dims=1))
hist(sum_cat[,1],
main = "TOTAL TIME OCCUPATION PER PLATFORM (LOG TRANSFORMATION)",
xlab = "TIME OCCUPATION",
ylab = "NUMBER OF PLATFORMS",
border = "blue",
breaks = 100,
col = "green")
sum_cat <- data.frame(total_time = colSums(data_log, na.rm = FALSE, dims=1))
hist(sum_cat[,1],
main = "TOTAL TIME OCCUPATION PER PLATFORM (Freedman-Diaconis)",
xlab = "TIME OCCUPATION",
ylab = "NUMBER OF PLATFORMS",
border = "blue",
breaks = "FD",
col = "green")
hist(sum_cat[,1],
main = "TOTAL TIME OCCUPATION PER PLATFORM (LOG TRANSFORMATION)",
xlab = "TIME OCCUPATION",
ylab = "NUMBER OF PLATFORMS",
border = "blue",
col = "green")
sum_time <- data.frame(total_time = rowSums(data_log, na.rm = FALSE, dims=1))
hist(sum_time[,1],
main = "TOTAL TIME OCCUPATION PER USER (LOG TRANSFORMATION)",
xlab = "TIME OCCUPATION",
ylab = "NUMBER OF USERS",
border = "blue",
col = "green",
breaks = 100)
hist(sum_time[,1],
main = "TOTAL TIME OCCUPATION PER USER (Freedman-Diaconis)",
xlab = "TIME OCCUPATION",
ylab = "NUMBER OF USERS",
breaks="FD",
border = "blue",
col = "green")
sum_cat <- data.frame(total_time = colSums(data_log, na.rm = FALSE, dims=1))
hist(sum_cat[,1],
main = "TOTAL TIME OCCUPATION PER PLATFORM (LOG TRANSFORMATION)",
xlab = "TIME OCCUPATION",
ylab = "NUMBER OF PLATFORMS",
border = "blue",
breaks = 100,
col = "green")
sum_cat <- data.frame(total_time = colSums(data_log, na.rm = FALSE, dims=1))
hist(sum_cat[,1],
main = "TOTAL TIME OCCUPATION PER PLATFORM (Freedman-Diaconis)",
xlab = "TIME OCCUPATION",
ylab = "NUMBER OF PLATFORMS",
border = "blue",
breaks = "FD",
col = "green")
